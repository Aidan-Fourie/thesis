{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbi:hide_in\n",
    "import pandas_datareader as pd2\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import keras as ks\n",
    "import matplotlib.pyplot as mp\n",
    "from keras.layers import Dense,LSTM,Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from ipywidgets import interact,interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbi:hide_in\n",
    "#WE DECLARE OUR CLASSES\n",
    "#THIS FUNCTION GETS, WINDOWS AND SPLITS INTO TEST/TRAIN\n",
    "class Data():\n",
    "    \n",
    "    def __init__(self,ticker,start,end):\n",
    "        self.data = pd2.DataReader(ticker,'yahoo', start, end).iloc[:,]\n",
    "        \n",
    "    def window(self,windows,col):\n",
    "        \n",
    "        #we sort the windowed array\n",
    "        windows = sorted(windows)\n",
    "\n",
    "        #we loop through the training data and restructure\n",
    "        for i in range(max(windows),self.data.count()[0]):\n",
    "\n",
    "            y_record = self.data.iloc[[i],:].loc[:,[col]]\n",
    "            x_record = self.data.iloc[[i-windows[0]],:].loc[:,[col]]\n",
    "            x_record.columns = str(windows[0]) + \"-\" + x_record.columns\n",
    "\n",
    "            if(len(windows)>1):\n",
    "\n",
    "                for j in range(1,len(windows)):\n",
    "                    x_temp   = self.data.iloc[[i-windows[j]],:].loc[:,[col]]\n",
    "                    x_temp.columns = str(windows[j]) + \"-\" + x_temp.columns\n",
    "                    x_record = pd.concat([x_record.reset_index(drop=True), x_temp.reset_index(drop=True)], axis=1)\n",
    "\n",
    "            if(i==max(windows)):\n",
    "                x_final = x_record\n",
    "                y_final = y_record\n",
    "            else:\n",
    "                x_final = x_final.append(x_record)\n",
    "                y_final = y_final.append(y_record)\n",
    "\n",
    "            self.features = x_final.set_index(y_final.index)\n",
    "            self.response = y_final\n",
    "            \n",
    "    def split_data(self,period):\n",
    "        self.test_features = self.features.iloc[self.features.count()[0]-period:self.features.count()[0],:]\n",
    "        self.train_features = self.features.iloc[0:self.features.count()[0]-period,:]\n",
    "        self.test_response = self.response.iloc[self.features.count()[0]-period:self.features.count()[0],:]\n",
    "        self.train_response = self.response.iloc[0:self.features.count()[0]-period,:]\n",
    "        self.data_train = self.data.iloc[0:self.data.count()[0]-period,:]\n",
    "        self.data_test =  self.data.iloc[self.data.count()[0]-period:self.data.count()[0],:]\n",
    "\n",
    "class NN():\n",
    "    \n",
    "    def __init__(self,neurons,activations):\n",
    "        self.neurons = neurons\n",
    "        self.activations = activations\n",
    "     \n",
    "    def create_model(self,dim,loss,optimizer):\n",
    "    \n",
    "        self.model = ks.Sequential()\n",
    "     \n",
    "        for i in range(0,len(self.neurons)):\n",
    "            neuron = self.neurons[i]\n",
    "            activation = self.activations[i]\n",
    "        \n",
    "            if(i == 0):\n",
    "                self.model.add(Dense(neuron,input_dim = dim,activation = activation))\n",
    "            else:\n",
    "                self.model.add(Dense(neuron,activation = activation))\n",
    "                \n",
    "        self.model.compile(loss=loss,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enter the instrument,start date,window period and test train split of the data required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ae0e879a4c49409f1b491dab655bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='AAPL,2014-04-04,2016-04-04', description='core'), Text(value='30,60,90', des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59031053910a4d36b7add833d7c084de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.data_build()>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This stores variables for data extract\n",
    "def data_store(core = 'NA', window = 'NA', valid = 'NA'):\n",
    "    \n",
    "    global ticker\n",
    "    global start\n",
    "    global end\n",
    "    global windows\n",
    "    global validation\n",
    "    \n",
    "    if core != 'NA':\n",
    "        temp = core.split(',')\n",
    "        ticker = temp[0]\n",
    "        start = temp[1]\n",
    "        end  = temp[2]\n",
    "        \n",
    "    if windows != 'NA':\n",
    "        windows = list(map(int,window.split(',')))\n",
    "        \n",
    "    if valid != 'NA':\n",
    "        validation = int(valid)\n",
    "\n",
    "\n",
    "#This extracts the data\n",
    "def data_build():\n",
    "    \n",
    "    global data\n",
    "\n",
    "    #we create the data model\n",
    "    data = Data(ticker,start,end)\n",
    "    data.window(windows,'Open')\n",
    "    data.split_data(validation)\n",
    "    #we plot the training and test\n",
    "    mp.figure(1)\n",
    "    mp.plot(data.train_response)\n",
    "    mp.plot(data.test_response)\n",
    "    mp.title('Train and Validation Split')\n",
    "    \n",
    "    #we plot the windowed data\n",
    "    mp.figure(2)\n",
    "    mp.plot(data.train_features)\n",
    "    mp.title('Training windowed data')\n",
    "\n",
    "\n",
    "interact(data_store,core ='AAPL,2014-04-04,2016-04-04',window='30,60,90',valid='90')\n",
    "interact_manual(data_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc132e49b904d0a8b36f18caf6acdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='3,3,1', description='neurons'), Text(value='linear,sigmoid,linear', descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a99ffa8bae24f368203f8e58307221e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.neural_network_build()>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neural_network_store(neurons,activations,epoch_in,batch_size_in,verbose_in):\n",
    "    global  neuron_array \n",
    "    global  activation_array \n",
    "    global  epochs\n",
    "    global  batch_size \n",
    "    global  verbose\n",
    "    \n",
    "    #organize inputs\n",
    "    neuron_array = list(map(int,neurons.split(',')))\n",
    "    activation_array = activations.split(',')\n",
    "    epochs = int(epoch_in)\n",
    "    batch_size = int(batch_size_in)\n",
    "    verbose = int(verbose_in)\n",
    "    \n",
    "    \n",
    "def neural_network_build():\n",
    "    global network\n",
    "    global history \n",
    "    \n",
    "    network = NN(neuron_array,activation_array)\n",
    "    network.create_model(dim=data.train_features.shape[1],loss='mse',optimizer='adam')\n",
    "    Stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=50, verbose=1, mode='auto', baseline=None)\n",
    "    history = network.model.fit(data.train_features,data.train_response.loc[:,'Open'],epochs=epochs,batch_size=batch_size,verbose=verbose,callbacks=[Stop],validation_data = (data.test_features,data.test_response.loc[:,'Open']))\n",
    "\n",
    "    #we plot the training and test\n",
    "    mp.figure(1)\n",
    "    mp.plot(data.train_response.index,network.model.predict(data.train_features))\n",
    "    mp.plot(data.train_response)\n",
    "    mp.title('Training and Prediction')\n",
    "    \n",
    "    #we plot the training and test\n",
    "    mp.figure(2)\n",
    "    mp.plot(data.test_response.index,network.model.predict(data.test_features))\n",
    "    mp.plot(data.test_response)\n",
    "    mp.title('Validation and Prediction')\n",
    "    \n",
    "    #we plot the training and test\n",
    "    mp.figure(3)\n",
    "    mp.plot(history.history['val_loss'])\n",
    "    mp.plot(history.history['loss'])\n",
    "    mp.title('Training and Validation Error')\n",
    "    \n",
    "interact(neural_network_store,neurons ='3,3,1',activations = 'linear,sigmoid,linear',epoch_in = '300',batch_size_in ='2',verbose_in = '1')\n",
    "interact_manual(neural_network_build)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [10499.004036458333,\n",
       "  10377.608333333334,\n",
       "  10037.087760416667,\n",
       "  9850.107845052084,\n",
       "  9712.3955078125,\n",
       "  9579.778038194445,\n",
       "  9449.447254774306,\n",
       "  9322.698307291666,\n",
       "  9197.082313368055,\n",
       "  9073.835633680555],\n",
       " 'loss': [13427.726438540054,\n",
       "  13164.335686556695,\n",
       "  12867.19288469911,\n",
       "  12591.501693111455,\n",
       "  12428.77001499613,\n",
       "  12276.153175188661,\n",
       "  12128.377754329527,\n",
       "  11983.764409587848,\n",
       "  11841.611325101587,\n",
       "  11701.54055908959]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
